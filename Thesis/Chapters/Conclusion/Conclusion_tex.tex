% Chapter Template

\chapter{Summary and Conclusions} % Main chapter title

\label{Conclusion} % for referencing this chapter elsewhere, use \ref{Conclusion}

Throughout this thesis, we have explored various methods relating to dose-finding methodologies and investigated how they could be applied in practical contexts through illustrative examples and real clinical trials. In this concluding chapter, we summarise our key points. 

We began in Chapter \ref{Adept} by detailing the PO-TTIE-CRM design \cite{wagesContinualReassessmentMethod2011, wagesUsingTimetoeventContinual2013} and our experiences implementing the design. Partial ordering was originally hypothesised for use in investigations of escalation in combination of multiple-agents. Depending on the doses selected its is possible in these scenarios the monotonicity assumption no longer holds. However our implementation, whilst also in a trial investigating combination treatment, observed partial ordering occur due to the dosing schedule of one of the treatments. This highlights the fact that this issue can also arise in multiple settings and more generally methodology can still be implemented in scenarios outside of its original purview.  

Via simulations we showcased the performance of the design and then contrasted that with potential alternatives. Even with the additional complexity of the design the operating characteristics were comparable across the varying designs. The caveat being that some of those alternatives would have to make concessions and assumptions about the dose-levels we were investigating. Without this methodology answering the relevant clinical question of the trial would become difficult. The doses selected for investigation were deemed clinically relevant and if we could not resolve the issue around the uncertainty of the order of the doses different doses would have had to been selected. 

Whilst for the development of a new drug typically the maximum tolerated dose (MTD) is of interest, for repurposed treatments or combination treatments there may be additional interest in also understanding the optimal dosing schedule. Whilst this was not one of the main aims of the trial it was of interest. An understanding of the best dosing schedule would then feed into the decision for what the final dose (dose-level 3) would eventually become based on the aggregate data. 

If biologically plausible that the same overall dose administered across a shorter duration is more or less toxic when administered over a longer duration then time window for administration may be more important to consider than overall dose. For example, if it is understood that 400mg of a specific drug over five days is more toxic than 400mg over 20 days, it doesn't always follow then that by increasing the overall dose we may be increasing toxicity. So, 401mg over 20 days may still be less toxic than 400mg over five. Obviously this is an extreme example but it could still be clinically relevant in some areas and maybe either warrant further research. The partial ordering approach is one way to solve this issue but their could potentially be more efficient methods.  

As the problem and issue of partial ordering is fairly unique there are not many approaches to dealing with it or accounts of practical applications. This may not be surprising considering it was only introduced in 2013 and it still shows there is somewhat of a lag between methodology being developed and implemented. One barrier we experienced was the limited availability of software. Along with the original methodology Nolan et al. \cite{wagesPocrmRpackagePhase2013, wagesPocrmDoseFinding2019} developed R functions for the implementation of the PO-CRM but not its time-to-event counterpart. However, having this as a basis to work from was extremely crucial in our success at implementing the design. Even still it took a bit of time and input from multiple statisticians to ensure this happened. From an academic perspective finding the resources in terms of time and statistical expertise may also be another barrier especially during initial design stages of a trial where there is limited funding. 

Our work also has the added benefit of validating the original PO-TITE-CRM design and confirming the results found in that paper. Whilst we did not directly replicate the exact work presented there we have reached similar conclusions. Hopefully, our account and experiences implementing this methodology will help others to do the same. We have shared this work through a poster presentation at ICTMC 2022 \cite{ICTMC20226th} and also with a publication currently in pre-print. The ADePT-DDR trial opened in August 2021 and is currently recruiting to its third cohort of patients. Due to practical and logistical issues some aspects of the design have been altered however, the underlying methodology used in the trial still remains the same. 

Following this chapter we explored the development of our own methodology which is specifically an extension we made to the Wages and Tait design \cite{wagesSeamlessPhaseII2015}. This design is considered an adaptive or seamless phase \RN{1}/\RN{2} design as it uses both toxicity and efficacy outcomes to obtain an optimal biological dose (OBD). However, just by including efficacy outcomes does not mean we fully eradicate the need to conduct a randomised phase \RN{2} study. We sought, through our design modification, to address this and have a trial design capable of conducting dose-finding and making direct comparisons to a control arm. 

By leveraging the adaptive randomisation mechanism we were able to force the design to allocate patients to a control arm. We demonstrated through simulations that the design worked as intended. A reasonable rate of selection for the OBD or "good" dose-levels was achieved along with allocating a sufficient number of patients to a control arm. By contrasting our design to potential alternatives we also showed there is minimal loss in terms of efficiency when using this modification. However, when it came to comparing the control arm to the OBD our results showed that we would be incredibly underpowered unless there was a rather large effect size. In order to improve this we would need to increase the overall sample size of the study or add expansion cohorts for both the OBD dose and control dose.   

We identify the most common situation in which it would be appropriate to implement this design is when investigating a new treatment in combination with some form of standard of care. Here there should be some understanding on the efficacy and toxicity profile of the standard of care treatment and this design would allow you to assess if there are any benefits to adding a new intervention to standard of care. An additional limitation of this work is that we only explored this design modification using one exemplar trial. Therefore, our results and overall conclusions of the design may be slightly different under a different example. 

There may also be issues with this design that we have not considered and would only become apparent when implementing the design. Simulations showed adequate allocation of patients to the control arm however, in practice we only run the trial once not 10,000 times so perhaps by chance we could end up with very few or limited patients in the control arm. So, we may want to consider changing our fixed rate of randomisation to control to also be adaptive dependent on the number of patients already in the control arm. Similarly, more work could be done to look at different randomisation mechanisms to allocate dose-levels. 

Overall it may still be more efficient to set up a trial in this manner rather than having an independent phase \RN{1} trial into an independent phase \RN{2} trial. This may be the future of trial designs where they are fully seamless and adaptive going through all the phases aiming to answer multiple questions with multiple decision points. You could imagine using our RtC-WT design to determine an OBD then potentially expand recruitment to confirm if there is enough of an efficacy signal to prompt a 'GO' decision for a fully randomised phase \RN{3} trial. If this was all incorporated into one trial you could save resources in terms of time and money. There may also be efficiency gains in directly borrowing information from patients within the same trial from previous phases. 

This work was motivated by a few potential trials being designed at the University of Birmingham's Cancer Research UK Clinical Trials Unit. Unfortunately, none of those trials came to fruition due to other circumstances, so the methodology itself is yet to be implemented.  

Chapter \ref{TITE-DTP} looked at applying dose transition pathways (DTPs) to trials using time-to-event methodology. The original paper by Yap et al. \cite{yapDoseTransitionPathways2017} touches on the issue of applying DTPs to designs like the TITE-CRM. The authors briefly discussed that projected DTPs can differ dependent on how information was available for each dose decision and that it would be difficult to map out decisions in advance. Our work delved into this issue deeper to detail the exact issues and to see if there were any potential solutions.

This work was also partly motivated by the ADePT-DDR trial as well. Due to the PO-TITE-CRM methodology and the long observation periods there was interest in mapping out decisions ahead of time to facilitate faster decision making and better communicate the decision that would be made throughout the trial. It quickly became apparent due to the length of the observation window (52 weeks post treatment) this would be unfeasible. 

Here we present the idea of combined follow-up time for patients in the same cohort at the same dose-level. By grouping together the follow-up times of each patient in a cohort we can then apply the TITE-CRM model for each combination of time in order to figure out what the dose decisions would be for each. Based on this we could then see how much information or combined follow-up was required to make specific dose decisions. During this process we made an interesting observation that depending on how the combined follow-up time was split between patients a different dose-decision could be made. We clarified that this was due to way in which the likelihood was calculated and that, at least for a linear weight function, patients weights are linear at the individual level but not at the cohort level. This could be a potential area for further research by investigating how the likelihood calculation is impacted by different weight functions and what impact that has on the dose recommendations being made. 

The other main issue in presenting TITE-DTPs comes from the number of possible outcomes that need to be mapped out. Even in our simple example of just a five week observation window, mapping out all the potential variations of outcomes for six patients results in more outcomes then seconds since the universe began.  Our suggested solution to this was to limit the pathways that were presented just to be for the next cohort assuming you had all the available data for all previous cohorts. This still does not help for trials with much longer observation windows. In these scenarios it would be suggested that outcomes be limited to plausible scenarios. For instance it is unlikely that you would recruit a cohort on one day and need to immediately make a dose-decision for a new patient on the next day. So, the number of outcomes could be simplified to just look at combined follow-up times which were appropriate or more realistic. Though, if the observation window is long enough this still may not be sufficient in reducing the number of outcomes. 

Anecdotally speaking DTPs appear to be one of best tools for communicating methodology in early phase trials. Especially when it comes to presenting the different decisions that can be made during a trial. I have received compliments from presenting DTPs whether it be patient representatives or independent clinicians sitting on data monitoring committees or representatives from pharma partners when setting up a trial. So, it would seem beneficial to try and extend DTPs or the concept of them for presenting decisions as far as possible in trials.  

Staying with that idea, Chapter \ref{etp} introduces efficacy transition pathways (ETPs). A visualisation tool inspired by DTPs but for use in phase \RN{2} trials. Much like DTPs they aim to better illustrate and communicate decisions made in these types of trials. We detail how ETPs can be constructed and how they can be used to assist during the running of a trial and the development of the trials design and stopping rules. 

Through three illustrative example trials we detailed how they have already begun to be implemented and used in practice. All three trials present ETPs in a similar manner however are all in slightly different settings. What became apparent from these implementations is that whilst theoretically simple to produce, ETPs were often time consuming to put together. The calculations required for presentation in the ETPs could be automated by constructing the plot could become laborious if other elements of the trial design were altered. This motivated us to develop software in order to allow for automatic generation of ETPs.      

We began by developing a simple function in R that could generate these plots. Around that we built a web based application using shiny. The app makes producing these plots even easier as it does not require the user to be familiar with any particular software package. All the inputs required for the function are presented in the app through various widgets. From the app there is the ability to download the ETP as an image additionally the user can also download a copy of the data used to generate the ETP. Other benefits of the app also allow us to include some interactivity with the ETP. By clicking on the plot the user can see additional information for the specific cell they clicked on. A larger version of the cell is produced, which is useful in cases where the ETP is rather large with lots of cells. A posterior distribution is also plotted based on the data in that cell showing other key information like credible intervals and the decision criteria.   

We also developed additional pages on the app to introduce some of the fundamentals required to understand ETPs. This is done mainly through text and images. However, we include interactive elements to explain the basics of beta-binomial conjugate analyses. Users can interact and specify different priors, likelihoods and decision rules and see how interpretations from the posterior distribution change accordingly. There is also the facilitate to simulate a practice trial so users can get an idea of how a trial designed in this way could work. All this additional content was incorporated in a way that is hopefully approachable by people with limited knowledge on these topics. We still envisage that these pages could be used by statisticians as well to also help explain these concepts to others. 

Even though the tools such as DTPs and ETPs are beneficial in and of themselves having the ability to automatically produce them by clicking a few buttons could further enhance how they are used. During discussions with clinicians you could easily demonstrate how changes to the design or decision criteria would affect the decisions made through the ETPs. The added layer of interactivity through the app could also assist the statistician in better communicating the changes that are being suggested. By developing all these materials and making them easily accessible we hope it makes ETP simple to implement where appropriate.

All the work presented in this thesis was motivated by the development of clinical trials at the University of Birmingham's Cancer Research UK Clinical Trials Unit. Novel methods are generally speaking very useful and valuable. In the context of dose-finding methodologies they can often times provide solutions to complex clinical questions without compromising efficacy or in some cases improve on it. Furthermore, the development of appropriate software and tools to facilitate decision making are equally important in advancing the implementation of these novel methods.  